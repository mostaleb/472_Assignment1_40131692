--------------------------------------------------
(A) Model Evaluation: Base-DT-Abalone Max Depth 3

(B) Confusion Matrix:
[[102  84 791]
 [ 69 743 194]
 [ 99 180 870]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.38      0.10      0.16       977
           I       0.74      0.74      0.74      1006
           M       0.47      0.76      0.58      1149

    accuracy                           0.55      3132
   macro avg       0.53      0.53      0.49      3132
weighted avg       0.53      0.55      0.50      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.49
Weighted-average F1: 0.50
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-DT-abalone', ' scoring=', 'accuracy', ' cv=', 5)

(B) Confusion Matrix:
[[345  75 557]
 [ 82 746 178]
 [251 158 740]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.51      0.35      0.42       977
           I       0.76      0.74      0.75      1006
           M       0.50      0.64      0.56      1149

    accuracy                           0.58      3132
   macro avg       0.59      0.58      0.58      3132
weighted avg       0.59      0.58      0.58      3132


(D) Model Performance Metrics:
Accuracy: 0.58
Macro-average F1: 0.58
Weighted-average F1: 0.58
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('mlp-abalone', ' activation=', 'logistic', ' solver=', 'sgd')

(B) Confusion Matrix:
[[   0   46  931]
 [   0  536  470]
 [   0  106 1043]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       977
           I       0.78      0.53      0.63      1006
           M       0.43      0.91      0.58      1149

    accuracy                           0.50      3132
   macro avg       0.40      0.48      0.40      3132
weighted avg       0.41      0.50      0.42      3132


(D) Model Performance Metrics:
Accuracy: 0.50
Macro-average F1: 0.40
Weighted-average F1: 0.42
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-mlp-abalone', ' scoring=', 'accuracy', ' cv=', 5, ' n_jobs=', -1)

(B) Confusion Matrix:
[[110 132 735]
 [  6 816 184]
 [ 65 235 849]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.61      0.11      0.19       977
           I       0.69      0.81      0.75      1006
           M       0.48      0.74      0.58      1149

    accuracy                           0.57      3132
   macro avg       0.59      0.55      0.51      3132
weighted avg       0.59      0.57      0.51      3132


(D) Model Performance Metrics:
Accuracy: 0.57
Macro-average F1: 0.51
Weighted-average F1: 0.51
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: Base-DT-Abalone Max Depth 3

(B) Confusion Matrix:
[[334 194 456]
 [ 62 839 103]
 [294 291 559]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.48      0.34      0.40       984
           I       0.63      0.84      0.72      1004
           M       0.50      0.49      0.49      1144

    accuracy                           0.55      3132
   macro avg       0.54      0.55      0.54      3132
weighted avg       0.54      0.55      0.54      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.54
Weighted-average F1: 0.54
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-DT-abalone', ' scoring=', 'accuracy', ' cv=', 5)

(B) Confusion Matrix:
[[365  79 540]
 [ 79 720 205]
 [275 146 723]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.51      0.37      0.43       984
           I       0.76      0.72      0.74      1004
           M       0.49      0.63      0.55      1144

    accuracy                           0.58      3132
   macro avg       0.59      0.57      0.57      3132
weighted avg       0.58      0.58      0.57      3132


(D) Model Performance Metrics:
Accuracy: 0.58
Macro-average F1: 0.57
Weighted-average F1: 0.57
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('mlp-abalone', ' activation=', 'logistic', ' solver=', 'sgd')

(B) Confusion Matrix:
[[  0 138 846]
 [  0 693 311]
 [  0 214 930]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       984
           I       0.66      0.69      0.68      1004
           M       0.45      0.81      0.58      1144

    accuracy                           0.52      3132
   macro avg       0.37      0.50      0.42      3132
weighted avg       0.38      0.52      0.43      3132


(D) Model Performance Metrics:
Accuracy: 0.52
Macro-average F1: 0.42
Weighted-average F1: 0.43
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-mlp-abalone', ' scoring=', 'accuracy', ' cv=', 5, ' n_jobs=', -1)

(B) Confusion Matrix:
[[497 125 362]
 [ 54 793 157]
 [488 221 435]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.48      0.51      0.49       984
           I       0.70      0.79      0.74      1004
           M       0.46      0.38      0.41      1144

    accuracy                           0.55      3132
   macro avg       0.54      0.56      0.55      3132
weighted avg       0.54      0.55      0.54      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.55
Weighted-average F1: 0.54
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: Base-DT-Abalone Max Depth 3

(B) Confusion Matrix:
[[128  93 752]
 [ 86 750 173]
 [111 188 851]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.13      0.20       973
           I       0.73      0.74      0.74      1009
           M       0.48      0.74      0.58      1150

    accuracy                           0.55      3132
   macro avg       0.53      0.54      0.50      3132
weighted avg       0.53      0.55      0.51      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.50
Weighted-average F1: 0.51
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-DT-abalone', ' scoring=', 'accuracy', ' cv=', 5)

(B) Confusion Matrix:
[[352  89 532]
 [ 89 749 171]
 [260 187 703]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.36      0.42       973
           I       0.73      0.74      0.74      1009
           M       0.50      0.61      0.55      1150

    accuracy                           0.58      3132
   macro avg       0.58      0.57      0.57      3132
weighted avg       0.57      0.58      0.57      3132


(D) Model Performance Metrics:
Accuracy: 0.58
Macro-average F1: 0.57
Weighted-average F1: 0.57
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('mlp-abalone', ' activation=', 'logistic', ' solver=', 'sgd')

(B) Confusion Matrix:
[[  0 124 849]
 [  0 685 324]
 [  0 218 932]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       973
           I       0.67      0.68      0.67      1009
           M       0.44      0.81      0.57      1150

    accuracy                           0.52      3132
   macro avg       0.37      0.50      0.42      3132
weighted avg       0.38      0.52      0.43      3132


(D) Model Performance Metrics:
Accuracy: 0.52
Macro-average F1: 0.42
Weighted-average F1: 0.43
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-mlp-abalone', ' scoring=', 'accuracy', ' cv=', 5, ' n_jobs=', -1)

(B) Confusion Matrix:
[[299 144 530]
 [ 25 822 162]
 [274 241 635]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.31      0.38       973
           I       0.68      0.81      0.74      1009
           M       0.48      0.55      0.51      1150

    accuracy                           0.56      3132
   macro avg       0.55      0.56      0.55      3132
weighted avg       0.55      0.56      0.55      3132


(D) Model Performance Metrics:
Accuracy: 0.56
Macro-average F1: 0.55
Weighted-average F1: 0.55
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: Base-DT-Abalone Max Depth 3

(B) Confusion Matrix:
[[   0   74  904]
 [   0  702  306]
 [   0  133 1013]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       978
           I       0.77      0.70      0.73      1008
           M       0.46      0.88      0.60      1146

    accuracy                           0.55      3132
   macro avg       0.41      0.53      0.44      3132
weighted avg       0.42      0.55      0.46      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.44
Weighted-average F1: 0.46
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-DT-abalone', ' scoring=', 'accuracy', ' cv=', 5)

(B) Confusion Matrix:
[[425 122 431]
 [ 79 812 117]
 [250 199 697]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.56      0.43      0.49       978
           I       0.72      0.81      0.76      1008
           M       0.56      0.61      0.58      1146

    accuracy                           0.62      3132
   macro avg       0.61      0.62      0.61      3132
weighted avg       0.61      0.62      0.61      3132


(D) Model Performance Metrics:
Accuracy: 0.62
Macro-average F1: 0.61
Weighted-average F1: 0.61
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('mlp-abalone', ' activation=', 'logistic', ' solver=', 'sgd')

(B) Confusion Matrix:
[[  0  85 893]
 [  0 681 327]
 [  0 161 985]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       978
           I       0.73      0.68      0.70      1008
           M       0.45      0.86      0.59      1146

    accuracy                           0.53      3132
   macro avg       0.39      0.51      0.43      3132
weighted avg       0.40      0.53      0.44      3132


(D) Model Performance Metrics:
Accuracy: 0.53
Macro-average F1: 0.43
Weighted-average F1: 0.44
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-mlp-abalone', ' scoring=', 'accuracy', ' cv=', 5, ' n_jobs=', -1)

(B) Confusion Matrix:
[[201  98 679]
 [ 11 760 237]
 [143 196 807]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.57      0.21      0.30       978
           I       0.72      0.75      0.74      1008
           M       0.47      0.70      0.56      1146

    accuracy                           0.56      3132
   macro avg       0.59      0.55      0.53      3132
weighted avg       0.58      0.56      0.54      3132


(D) Model Performance Metrics:
Accuracy: 0.56
Macro-average F1: 0.53
Weighted-average F1: 0.54
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: Base-DT-Abalone Max Depth 3

(B) Confusion Matrix:
[[113 108 754]
 [ 76 753 194]
 [101 177 856]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.12      0.18       975
           I       0.73      0.74      0.73      1023
           M       0.47      0.75      0.58      1134

    accuracy                           0.55      3132
   macro avg       0.53      0.54      0.50      3132
weighted avg       0.53      0.55      0.51      3132


(D) Model Performance Metrics:
Accuracy: 0.55
Macro-average F1: 0.50
Weighted-average F1: 0.51
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-DT-abalone', ' scoring=', 'accuracy', ' cv=', 5)

(B) Confusion Matrix:
[[390 127 458]
 [ 79 806 138]
 [217 209 708]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.57      0.40      0.47       975
           I       0.71      0.79      0.74      1023
           M       0.54      0.62      0.58      1134

    accuracy                           0.61      3132
   macro avg       0.61      0.60      0.60      3132
weighted avg       0.60      0.61      0.60      3132


(D) Model Performance Metrics:
Accuracy: 0.61
Macro-average F1: 0.60
Weighted-average F1: 0.60
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('mlp-abalone', ' activation=', 'logistic', ' solver=', 'sgd')

(B) Confusion Matrix:
[[  0 148 827]
 [  0 695 328]
 [  0 224 910]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       975
           I       0.65      0.68      0.67      1023
           M       0.44      0.80      0.57      1134

    accuracy                           0.51      3132
   macro avg       0.36      0.49      0.41      3132
weighted avg       0.37      0.51      0.42      3132


(D) Model Performance Metrics:
Accuracy: 0.51
Macro-average F1: 0.41
Weighted-average F1: 0.42
--------------------------------------------------
--------------------------------------------------
(A) Model Evaluation: ('Top-mlp-abalone', ' scoring=', 'accuracy', ' cv=', 5, ' n_jobs=', -1)

(B) Confusion Matrix:
[[595 126 254]
 [119 778 126]
 [636 205 293]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.44      0.61      0.51       975
           I       0.70      0.76      0.73      1023
           M       0.44      0.26      0.32      1134

    accuracy                           0.53      3132
   macro avg       0.53      0.54      0.52      3132
weighted avg       0.52      0.53      0.52      3132


(D) Model Performance Metrics:
Accuracy: 0.53
Macro-average F1: 0.52
Weighted-average F1: 0.52
--------------------------------------------------
